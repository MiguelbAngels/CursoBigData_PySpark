{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Curso Big Data #2 - SparkSession crear y leer DataFrames en PySpark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Librer칤as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SparkSession\n",
    "\n",
    "La *SparkSession*, introducida en la versi칩n Spark 2.0, es un punto de entrada a las funcionalidades de Spark. El objeto SparkSession de spark est치 disponible de forma predeterminada en spark-shell, tecleando en un terminal de nuestro pc **pyspark**:\n",
    "\n",
    "```bash\n",
    "C:\\Users\\errodringer\\suscribete>pyspark\n",
    "```\n",
    "\n",
    "en la variable **spark**:\n",
    "\n",
    "![spark-shell](images/spark-shell.PNG \"Spark-Shell\")  \n",
    "\n",
    "Aunque *SparkContext* sol칤a ser el punto de entrada antes de la versi칩n 2.0 de Spark, no se reemplaza completamente con SparkSession, muchas caracter칤sticas de SparkContext todav칤a est치n disponibles y se usan en Spark 2.0 y versiones posteriores. La SparkSession crea internamente SparkConfig y SparkContext con la configuraci칩n proporcionada."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Crear la SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('firstSession')\\\n",
    "    .config('spark.master', 'local[4]')\\\n",
    "    .config('spark.executor.memory', '1g')\\\n",
    "    .config(\"spark.sql.shuffle.partitions\", 1)\\\n",
    "    .config('spark.driver.memory','1g')\\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Todas las condifuraciones disponibles en Spark:\n",
    "\n",
    "https://spark.apache.org/docs/latest/configuration.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://DESKTOP-1EE24UT:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.1.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[4]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>firstSession</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x254e269de10>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se puede obtener y cambiar la configuraci칩n inicial dada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.conf.get('spark.sql.shuffle.partitions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.conf.set(\"spark.sql.shuffle.partitions\", 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.conf.get('spark.sql.shuffle.partitions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('spark.sql.shuffle.partitions', '1'),\n",
       " ('spark.app.name', 'firstSession'),\n",
       " ('spark.driver.host', 'DESKTOP-1EE24UT'),\n",
       " ('spark.master', 'local[4]'),\n",
       " ('spark.executor.id', 'driver'),\n",
       " ('spark.driver.memory', '1g'),\n",
       " ('spark.driver.port', '65081'),\n",
       " ('spark.app.id', 'local-1618732648653'),\n",
       " ('spark.sql.warehouse.dir',\n",
       "  'file:/C:/Users/rodgo/errodringer/cursoBigData/02_PrimerosPasosConPySpark/code/spark-warehouse'),\n",
       " ('spark.executor.memory', '1g'),\n",
       " ('spark.rdd.compress', 'True'),\n",
       " ('spark.serializer.objectStreamReset', '100'),\n",
       " ('spark.app.startTime', '1618732647355'),\n",
       " ('spark.submit.pyFiles', ''),\n",
       " ('spark.submit.deployMode', 'client'),\n",
       " ('spark.default.parallelism', '4'),\n",
       " ('spark.ui.showConsoleProgress', 'true')]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sparkContext.getConf().getAll()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con el comando:\n",
    "\n",
    "```python\n",
    "spark.stop()\n",
    "```\n",
    "\n",
    "detenemos la aplicaci칩n. Lo veremos al final, ahora no interesa parar 游땢"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Crear tabla"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 A partir de una lista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 'Errodringer', 'a'),\n",
       " (2, 'Paco', 'b'),\n",
       " (3, 'Hola', 'c'),\n",
       " (4, 'Adios', 'd')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columnas = [\"id\", \"nombre\", \"l\"]\n",
    "lista = [(1, \"Errodringer\", \"a\"), (2, \"Paco\", \"b\"), (3, \"Hola\", \"c\"), (4, \"Adios\", \"d\")]\n",
    "lista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = spark.createDataFrame(lista, schema=columnas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N칰mero total de registros (filas) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mostramos *n* registros, indicando este par치metro como entrada en la funci칩n:\n",
    "\n",
    "```\n",
    "show(n)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----------+---+\n",
      "| id|     nombre|  l|\n",
      "+---+-----------+---+\n",
      "|  1|Errodringer|  a|\n",
      "|  2|       Paco|  b|\n",
      "+---+-----------+---+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_1.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Columnas del DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['id', 'nombre', 'l']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Schema del DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: long (nullable = true)\n",
      " |-- nombre: string (nullable = true)\n",
      " |-- l: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_1.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resumen del DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+------+----+\n",
      "|summary|                id|nombre|   l|\n",
      "+-------+------------------+------+----+\n",
      "|  count|                 4|     4|   4|\n",
      "|   mean|               2.5|  null|null|\n",
      "| stddev|1.2909944487358056|  null|null|\n",
      "|    min|                 1| Adios|   a|\n",
      "|    max|                 4|  Paco|   d|\n",
      "+-------+------------------+------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_1.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType\n",
    "\n",
    "schema_1 = StructType([\n",
    "    StructField(\"id\", IntegerType(), True),\n",
    "    StructField(\"name\", StringType(), True),\n",
    "    StructField(\"l\", StringType(), True)])\n",
    "\n",
    "df_11 = spark.createDataFrame(lista, schema=schema_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: integer (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- l: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_11.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----------+---+\n",
      "| id|       name|  l|\n",
      "+---+-----------+---+\n",
      "|  1|Errodringer|  a|\n",
      "|  2|       Paco|  b|\n",
      "|  3|       Hola|  c|\n",
      "|  4|      Adios|  d|\n",
      "+---+-----------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_11.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 A partir de un csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv('data/business.csv', sep=',', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-------+----------+----------+------+-------+---------+--------------------+--------------------+--------------------+--------------------+--------------+--------------+--------------+\n",
      "|Series_reference| Period|Data_value|Suppressed|STATUS|  UNITS|Magnitude|             Subject|               Group|      Series_title_1|      Series_title_2|Series_title_3|Series_title_4|Series_title_5|\n",
      "+----------------+-------+----------+----------+------+-------+---------+--------------------+--------------------+--------------------+--------------------+--------------+--------------+--------------+\n",
      "|   BDCQ.SF1AA2CA|2016.06|  1116.386|      null|     F|Dollars|        6|Business Data Col...|Industry by finan...|Sales (operating ...|Forestry and Logging|Current prices|    Unadjusted|          null|\n",
      "|   BDCQ.SF1AA2CA|2016.09|  1070.874|      null|     F|Dollars|        6|Business Data Col...|Industry by finan...|Sales (operating ...|Forestry and Logging|Current prices|    Unadjusted|          null|\n",
      "|   BDCQ.SF1AA2CA|2016.12|  1054.408|      null|     F|Dollars|        6|Business Data Col...|Industry by finan...|Sales (operating ...|Forestry and Logging|Current prices|    Unadjusted|          null|\n",
      "|   BDCQ.SF1AA2CA|2017.03|  1010.665|      null|     F|Dollars|        6|Business Data Col...|Industry by finan...|Sales (operating ...|Forestry and Logging|Current prices|    Unadjusted|          null|\n",
      "|   BDCQ.SF1AA2CA|2017.06|    1233.7|      null|     F|Dollars|        6|Business Data Col...|Industry by finan...|Sales (operating ...|Forestry and Logging|Current prices|    Unadjusted|          null|\n",
      "+----------------+-------+----------+----------+------+-------+---------+--------------------+--------------------+--------------------+--------------------+--------------+--------------+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-------+----------+----------+------+-------+---------+------------------------------+------------------------------+------------------------+--------------------+--------------+--------------+--------------+\n",
      "|Series_reference|Period |Data_value|Suppressed|STATUS|UNITS  |Magnitude|Subject                       |Group                         |Series_title_1          |Series_title_2      |Series_title_3|Series_title_4|Series_title_5|\n",
      "+----------------+-------+----------+----------+------+-------+---------+------------------------------+------------------------------+------------------------+--------------------+--------------+--------------+--------------+\n",
      "|BDCQ.SF1AA2CA   |2016.06|1116.386  |null      |F     |Dollars|6        |Business Data Collection - BDC|Industry by financial variable|Sales (operating income)|Forestry and Logging|Current prices|Unadjusted    |null          |\n",
      "|BDCQ.SF1AA2CA   |2016.09|1070.874  |null      |F     |Dollars|6        |Business Data Collection - BDC|Industry by financial variable|Sales (operating income)|Forestry and Logging|Current prices|Unadjusted    |null          |\n",
      "|BDCQ.SF1AA2CA   |2016.12|1054.408  |null      |F     |Dollars|6        |Business Data Collection - BDC|Industry by financial variable|Sales (operating income)|Forestry and Logging|Current prices|Unadjusted    |null          |\n",
      "|BDCQ.SF1AA2CA   |2017.03|1010.665  |null      |F     |Dollars|6        |Business Data Collection - BDC|Industry by financial variable|Sales (operating income)|Forestry and Logging|Current prices|Unadjusted    |null          |\n",
      "|BDCQ.SF1AA2CA   |2017.06|1233.7    |null      |F     |Dollars|6        |Business Data Collection - BDC|Industry by financial variable|Sales (operating income)|Forestry and Logging|Current prices|Unadjusted    |null          |\n",
      "+----------------+-------+----------+----------+------+-------+---------+------------------------------+------------------------------+------------------------+--------------------+--------------+--------------+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Series_reference: string (nullable = true)\n",
      " |-- Period: string (nullable = true)\n",
      " |-- Data_value: string (nullable = true)\n",
      " |-- Suppressed: string (nullable = true)\n",
      " |-- STATUS: string (nullable = true)\n",
      " |-- UNITS: string (nullable = true)\n",
      " |-- Magnitude: string (nullable = true)\n",
      " |-- Subject: string (nullable = true)\n",
      " |-- Group: string (nullable = true)\n",
      " |-- Series_title_1: string (nullable = true)\n",
      " |-- Series_title_2: string (nullable = true)\n",
      " |-- Series_title_3: string (nullable = true)\n",
      " |-- Series_title_4: string (nullable = true)\n",
      " |-- Series_title_5: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1936"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Escritura de un DataFrame. En este caso a ficheros tipo *parquet*, un formato de fichero optimizado para trabajar en entornos big data con grandes volumenes de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.write.parquet(\"parquet_example\", mode='overwrite')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se ha escrito en un 칰nico fichero porque el dataframe lo tenemos en una sola partici칩n."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 A partir de un parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_p = spark.read.parquet('parquet_example')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1936"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_p.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-------+----------+----------+------+-------+---------+--------------------+--------------------+--------------------+--------------------+--------------+--------------+--------------+\n",
      "|Series_reference| Period|Data_value|Suppressed|STATUS|  UNITS|Magnitude|             Subject|               Group|      Series_title_1|      Series_title_2|Series_title_3|Series_title_4|Series_title_5|\n",
      "+----------------+-------+----------+----------+------+-------+---------+--------------------+--------------------+--------------------+--------------------+--------------+--------------+--------------+\n",
      "|   BDCQ.SF1AA2CA|2016.06|  1116.386|      null|     F|Dollars|        6|Business Data Col...|Industry by finan...|Sales (operating ...|Forestry and Logging|Current prices|    Unadjusted|          null|\n",
      "|   BDCQ.SF1AA2CA|2016.09|  1070.874|      null|     F|Dollars|        6|Business Data Col...|Industry by finan...|Sales (operating ...|Forestry and Logging|Current prices|    Unadjusted|          null|\n",
      "+----------------+-------+----------+----------+------+-------+---------+--------------------+--------------------+--------------------+--------------------+--------------+--------------+--------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_p.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------------+------------------+------------------+----------+------+-------+---------+--------------------+--------------------+--------------------+--------------------+--------------+--------------+--------------+\n",
      "|summary|Series_reference|            Period|        Data_value|Suppressed|STATUS|  UNITS|Magnitude|             Subject|               Group|      Series_title_1|      Series_title_2|Series_title_3|Series_title_4|Series_title_5|\n",
      "+-------+----------------+------------------+------------------+----------+------+-------+---------+--------------------+--------------------+--------------------+--------------------+--------------+--------------+--------------+\n",
      "|  count|            1936|              1936|              1936|         0|  1936|   1936|     1936|                1936|                1936|                1936|                1936|          1936|          1936|             0|\n",
      "|   mean|            null| 2018.217975206615|2704.3055568181853|      null|  null|   null|      6.0|                null|                null|                null|                null|          null|          null|          null|\n",
      "| stddev|            null|1.3594869192539778| 4630.441460229322|      null|  null|   null|      0.0|                null|                null|                null|                null|          null|          null|          null|\n",
      "|    min|   BDCQ.SF1AA2CA|           2016.06|          -398.194|      null|     F|Dollars|        6|Business Data Col...|Industry by finan...|    Operating profit|Accommodation and...|Current prices|    Unadjusted|          null|\n",
      "|    max|   BDCQ.SF8RS2CA|           2020.12|           998.124|      null|     R|Dollars|        6|Business Data Col...|Industry by finan...|Sales (operating ...|Wood and Paper Pr...|Current prices|    Unadjusted|          null|\n",
      "+-------+----------------+------------------+------------------+----------+------+-------+---------+--------------------+--------------------+--------------------+--------------------+--------------+--------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_p.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pandas = df_p.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Series_reference</th>\n",
       "      <th>Period</th>\n",
       "      <th>Data_value</th>\n",
       "      <th>Suppressed</th>\n",
       "      <th>STATUS</th>\n",
       "      <th>UNITS</th>\n",
       "      <th>Magnitude</th>\n",
       "      <th>Subject</th>\n",
       "      <th>Group</th>\n",
       "      <th>Series_title_1</th>\n",
       "      <th>Series_title_2</th>\n",
       "      <th>Series_title_3</th>\n",
       "      <th>Series_title_4</th>\n",
       "      <th>Series_title_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BDCQ.SF1AA2CA</td>\n",
       "      <td>2016.06</td>\n",
       "      <td>1116.386</td>\n",
       "      <td>None</td>\n",
       "      <td>F</td>\n",
       "      <td>Dollars</td>\n",
       "      <td>6</td>\n",
       "      <td>Business Data Collection - BDC</td>\n",
       "      <td>Industry by financial variable</td>\n",
       "      <td>Sales (operating income)</td>\n",
       "      <td>Forestry and Logging</td>\n",
       "      <td>Current prices</td>\n",
       "      <td>Unadjusted</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BDCQ.SF1AA2CA</td>\n",
       "      <td>2016.09</td>\n",
       "      <td>1070.874</td>\n",
       "      <td>None</td>\n",
       "      <td>F</td>\n",
       "      <td>Dollars</td>\n",
       "      <td>6</td>\n",
       "      <td>Business Data Collection - BDC</td>\n",
       "      <td>Industry by financial variable</td>\n",
       "      <td>Sales (operating income)</td>\n",
       "      <td>Forestry and Logging</td>\n",
       "      <td>Current prices</td>\n",
       "      <td>Unadjusted</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BDCQ.SF1AA2CA</td>\n",
       "      <td>2016.12</td>\n",
       "      <td>1054.408</td>\n",
       "      <td>None</td>\n",
       "      <td>F</td>\n",
       "      <td>Dollars</td>\n",
       "      <td>6</td>\n",
       "      <td>Business Data Collection - BDC</td>\n",
       "      <td>Industry by financial variable</td>\n",
       "      <td>Sales (operating income)</td>\n",
       "      <td>Forestry and Logging</td>\n",
       "      <td>Current prices</td>\n",
       "      <td>Unadjusted</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BDCQ.SF1AA2CA</td>\n",
       "      <td>2017.03</td>\n",
       "      <td>1010.665</td>\n",
       "      <td>None</td>\n",
       "      <td>F</td>\n",
       "      <td>Dollars</td>\n",
       "      <td>6</td>\n",
       "      <td>Business Data Collection - BDC</td>\n",
       "      <td>Industry by financial variable</td>\n",
       "      <td>Sales (operating income)</td>\n",
       "      <td>Forestry and Logging</td>\n",
       "      <td>Current prices</td>\n",
       "      <td>Unadjusted</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BDCQ.SF1AA2CA</td>\n",
       "      <td>2017.06</td>\n",
       "      <td>1233.7</td>\n",
       "      <td>None</td>\n",
       "      <td>F</td>\n",
       "      <td>Dollars</td>\n",
       "      <td>6</td>\n",
       "      <td>Business Data Collection - BDC</td>\n",
       "      <td>Industry by financial variable</td>\n",
       "      <td>Sales (operating income)</td>\n",
       "      <td>Forestry and Logging</td>\n",
       "      <td>Current prices</td>\n",
       "      <td>Unadjusted</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Series_reference   Period Data_value Suppressed STATUS    UNITS Magnitude  \\\n",
       "0    BDCQ.SF1AA2CA  2016.06   1116.386       None      F  Dollars         6   \n",
       "1    BDCQ.SF1AA2CA  2016.09   1070.874       None      F  Dollars         6   \n",
       "2    BDCQ.SF1AA2CA  2016.12   1054.408       None      F  Dollars         6   \n",
       "3    BDCQ.SF1AA2CA  2017.03   1010.665       None      F  Dollars         6   \n",
       "4    BDCQ.SF1AA2CA  2017.06     1233.7       None      F  Dollars         6   \n",
       "\n",
       "                          Subject                           Group  \\\n",
       "0  Business Data Collection - BDC  Industry by financial variable   \n",
       "1  Business Data Collection - BDC  Industry by financial variable   \n",
       "2  Business Data Collection - BDC  Industry by financial variable   \n",
       "3  Business Data Collection - BDC  Industry by financial variable   \n",
       "4  Business Data Collection - BDC  Industry by financial variable   \n",
       "\n",
       "             Series_title_1        Series_title_2  Series_title_3  \\\n",
       "0  Sales (operating income)  Forestry and Logging  Current prices   \n",
       "1  Sales (operating income)  Forestry and Logging  Current prices   \n",
       "2  Sales (operating income)  Forestry and Logging  Current prices   \n",
       "3  Sales (operating income)  Forestry and Logging  Current prices   \n",
       "4  Sales (operating income)  Forestry and Logging  Current prices   \n",
       "\n",
       "  Series_title_4 Series_title_5  \n",
       "0     Unadjusted           None  \n",
       "1     Unadjusted           None  \n",
       "2     Unadjusted           None  \n",
       "3     Unadjusted           None  \n",
       "4     Unadjusted           None  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pandas.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
